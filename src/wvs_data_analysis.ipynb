{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import \n",
    "import pandas as pd\n",
    "\n",
    "# Import custom libraries\n",
    "import util\n",
    "from util import UtilityFunctions as uf\n",
    "\n",
    "# reload the custom library, \n",
    "# Need to be executed every time new functions are added to util.py \n",
    "from importlib import reload\n",
    "reload(util)   \n",
    "\n",
    "# Monkey patch the method from the utility class to the pandas DataFrame\n",
    "pd.DataFrame.filter_features = uf.filter_features\n",
    "pd.DataFrame.filter_numerical_values = uf.filter_numerical_values\n",
    "pd.DataFrame.filter_negative_values = uf.filter_negative_values\n",
    "pd.DataFrame.filter_columns_with_less_unique_values_than_threshold = uf.filter_columns_with_less_unique_values_than_threshold\n",
    "pd.DataFrame.drop_columns = uf.drop_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./../data/raw/WV3_Data_csv_v20180912.csv', './../data/raw/WV4_Data_csv_v20201117.csv', './../data/raw/WV5_Data_csv_v20180912.csv', './../data/raw/WV6_Data_csv_v20201117.csv', './../data/raw/WV7_Cross-National_Wave_7_csv_v6_0.csv']\n"
     ]
    }
   ],
   "source": [
    "raw_files = sorted(uf.get_csv_files_from_folder())  # Sort the list of files in ascending order\n",
    "print(raw_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "specific_columns = ['C_COW_ALPHA','B_COUNTRY_ALPHA','COW', 'V2','V2A']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw files: ['./../data/raw/WV3_Data_csv_v20180912.csv', './../data/raw/WV4_Data_csv_v20201117.csv', './../data/raw/WV5_Data_csv_v20180912.csv', './../data/raw/WV6_Data_csv_v20201117.csv', './../data/raw/WV7_Cross-National_Wave_7_csv_v6_0.csv']\n",
      "\n",
      "First 5 rows of ./../data/raw/WV3_Data_csv_v20180912.csv:\n",
      "Warning: Missing columns in ./../data/raw/WV3_Data_csv_v20180912.csv: C_COW_ALPHA, B_COUNTRY_ALPHA\n",
      "   COW  V2  V2A\n",
      "0  339   8    8\n",
      "1  339   8    8\n",
      "2  339   8    8\n",
      "3  339   8    8\n",
      "4  339   8    8\n",
      "\n",
      "First 5 rows of ./../data/raw/WV4_Data_csv_v20201117.csv:\n",
      "  C_COW_ALPHA B_COUNTRY_ALPHA  COW  V2  V2A\n",
      "0         ALB             ALB  339   8    8\n",
      "1         ALB             ALB  339   8    8\n",
      "2         ALB             ALB  339   8    8\n",
      "3         ALB             ALB  339   8    8\n",
      "4         ALB             ALB  339   8    8\n",
      "\n",
      "First 5 rows of ./../data/raw/WV5_Data_csv_v20180912.csv:\n",
      "Warning: Missing columns in ./../data/raw/WV5_Data_csv_v20180912.csv: C_COW_ALPHA, B_COUNTRY_ALPHA\n",
      "   COW  V2  V2A\n",
      "0  232  20   20\n",
      "1  232  20   20\n",
      "2  232  20   20\n",
      "3  232  20   20\n",
      "4  232  20   20\n",
      "\n",
      "First 5 rows of ./../data/raw/WV6_Data_csv_v20201117.csv:\n",
      "  C_COW_ALPHA B_COUNTRY_ALPHA  COW  V2  V2A\n",
      "0         ALG             DZA  615  12   12\n",
      "1         ALG             DZA  615  12   12\n",
      "2         ALG             DZA  615  12   12\n",
      "3         ALG             DZA  615  12   12\n",
      "4         ALG             DZA  615  12   12\n",
      "\n",
      "First 5 rows of ./../data/raw/WV7_Cross-National_Wave_7_csv_v6_0.csv:\n",
      "Warning: Missing columns in ./../data/raw/WV7_Cross-National_Wave_7_csv_v6_0.csv: COW, V2, V2A\n",
      "  C_COW_ALPHA B_COUNTRY_ALPHA\n",
      "0         AND             AND\n",
      "1         AND             AND\n",
      "2         AND             AND\n",
      "3         AND             AND\n",
      "4         AND             AND\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Print the list of raw files\n",
    "print(f\"Raw files: {raw_files}\")\n",
    "\n",
    "# Function to detect delimiter\n",
    "def detect_delimiter(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        sample = f.readline()\n",
    "        if ';' in sample and ',' not in sample:\n",
    "            return ';'\n",
    "        elif ',' in sample and ';' not in sample:\n",
    "            return ','\n",
    "        else:\n",
    "            # Default to ',' if both are present\n",
    "            return ';'\n",
    "\n",
    "# Loop through each file and print the first 5 rows (including column names) for specific columns\n",
    "for csv_file in raw_files:\n",
    "    print(f\"\\nFirst 5 rows of {csv_file}:\")\n",
    "    \n",
    "    try:\n",
    "        # Detect the delimiter\n",
    "        delimiter = detect_delimiter(csv_file)\n",
    "\n",
    "        # Try to read the CSV file into a dataframe\n",
    "        dataframe = pd.read_csv(csv_file, on_bad_lines='skip', delimiter=delimiter, low_memory=False)\n",
    "\n",
    "        # Check which columns from specific_columns are available in the dataframe\n",
    "        available_columns = [col for col in specific_columns if col in dataframe.columns]\n",
    "        missing_columns = [col for col in specific_columns if col not in dataframe.columns]\n",
    "\n",
    "        # If there are missing columns, print which ones are missing\n",
    "        if missing_columns:\n",
    "            print(f\"Warning: Missing columns in {csv_file}: {', '.join(missing_columns)}\")\n",
    "\n",
    "        # Read only the available columns (if any columns are missing, it will still load the available ones)\n",
    "        dataframe = dataframe[available_columns]\n",
    "\n",
    "        # Print the first 5 rows including the available column names\n",
    "        print(dataframe.head())\n",
    "\n",
    "    except pd.errors.ParserError as e:\n",
    "        print(f\"Error reading {csv_file}: {e}\")\n",
    "    except ValueError as e:\n",
    "        print(f\"ValueError in {csv_file}: {e} - Columns not found.\")\n",
    "        print(f\"Missing columns in {csv_file}: {', '.join(missing_columns)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = [(208, 'Denmark'), (578, 'Norway'), (276, 'Germany'), (87, 'USA')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw files: ['./../data/raw/WV3_Data_csv_v20180912.csv', './../data/raw/WV4_Data_csv_v20201117.csv', './../data/raw/WV5_Data_csv_v20180912.csv', './../data/raw/WV6_Data_csv_v20201117.csv', './../data/raw/WV7_Cross-National_Wave_7_csv_v6_0.csv']\n",
      "\n",
      "Checking country codes in ./../data/raw/WV3_Data_csv_v20180912.csv:\n",
      "Warning: Missing columns in ./../data/raw/WV3_Data_csv_v20180912.csv: C_COW_ALPHA, B_COUNTRY_ALPHA\n",
      "\n",
      "Unique values for column 'COW':\n",
      "[339 160 371 900 373 771 370 346 355 100 344 316 155 710  42  92 366 375\n",
      " 372 265 260 200 310 750 740 367 368 343  70 359 341 920 475 385 770 135\n",
      " 840 290   6 360 365 345 317 349 560 732 230   0 380 225 713 640 369 165\n",
      "   2 101 140]\n",
      "\n",
      "Unique values for column 'V2':\n",
      "[  8  32  51  36  31  50 112 914 100 170 191 203 152 156 214 222 233 246\n",
      " 268 276 826 348 356 392 428 440 807 484 498 912 554 566 578 586 604 608\n",
      " 616 630 642 643 911 703 705 710 410 724 101 752 756 158 792 804 858 840\n",
      " 862  76]\n",
      "  Found country: Norway (578) in column 'V2'\n",
      "  Found country: Germany (276) in column 'V2'\n",
      "\n",
      "Unique values for column 'V2A':\n",
      "[  8  32  51  36  31  50 112 914 100 170 191 203 152 156 214 222 233 246\n",
      " 268 901 900 826 348 356 392 428 440 807 484 498 912 554 566 578 586 604\n",
      " 608 616 630 642 643 911 703 705 710 410 724 101 752 756 158 792 804 858\n",
      " 840 862  76]\n",
      "  Found country: Norway (578) in column 'V2A'\n",
      "\n",
      "Checking country codes in ./../data/raw/WV4_Data_csv_v20201117.csv:\n",
      "\n",
      "Unique values for column 'C_COW_ALPHA':\n",
      "['ALB' 'ALG' 'ARG' 'BNG' 'BOS' 'CAN' 'CHL' 'CHN' 'DRV' 'EGY' 'IND' 'INS'\n",
      " 'IRN' 'IRQ' 'ISR' 'JOR' 'JPN' 'KYR' 'MAC' 'MEX' 'MLD' 'MNG' 'MOR' 'NIG'\n",
      " 'PAK' 'PER' 'PHI' 'PRI' 'ROK' 'SAF' 'SAU' 'SIN' 'SPN' 'SRB' 'SWD' 'TAZ'\n",
      " 'TUR' 'UGA' 'USA' 'VEN' 'ZIM']\n",
      "\n",
      "Unique values for column 'B_COUNTRY_ALPHA':\n",
      "['ALB' 'DZA' 'ARG' 'BGD' 'BIH' 'CAN' 'CHL' 'CHN' 'VNM' 'EGY' 'IND' 'IDN'\n",
      " 'IRN' 'IRQ' 'ISR' 'JOR' 'JPN' 'KGZ' 'MKD' 'MEX' 'MDA' 'MNE' 'MAR' 'NGA'\n",
      " 'PAK' 'PER' 'PHL' 'PRI' 'KOR' 'ZAF' 'SAU' 'SGP' 'ESP' 'SRB' 'SWE' 'TZA'\n",
      " 'TUR' 'UGA' 'USA' 'VEN' 'ZWE']\n",
      "\n",
      "Unique values for column 'COW':\n",
      "[339 615 160 771 346  20 155 710 816 651 750 850 630 645 666 663 740 703\n",
      " 343  70 359 341 600 475 770 135 840   6 732 560 670 830 230 345 380 510\n",
      " 640 500   2 101 552]\n",
      "\n",
      "Unique values for column 'V2':\n",
      "[  8  12  32  50  70 124 152 156 704 818 356 360 364 368 376 400 392 417\n",
      " 807 484 498 499 504 566 586 604 608 630 410 710 682 702 724 688 752 834\n",
      " 792 800 840 862 716]\n",
      "\n",
      "Unique values for column 'V2A':\n",
      "[  8  12  32  50  70 124 152 156 704 818 356 360 364 368 376 400 392 417\n",
      " 807 484 498 499 504 566 586 604 608 630 410 710 682 702 724 688 752 834\n",
      " 792 800 840 862 716]\n",
      "\n",
      "Checking country codes in ./../data/raw/WV5_Data_csv_v20180912.csv:\n",
      "Warning: Missing columns in ./../data/raw/WV5_Data_csv_v20180912.csv: C_COW_ALPHA, B_COUNTRY_ALPHA\n",
      "\n",
      "Unique values for column 'COW':\n",
      "[232 160 900 140 355 439  20 100 352 155 710 651 530 375 220 372 255 452\n",
      "  90 714 310 750 850 630 645 325 740 663 820 432  70 359 600 210 920 385\n",
      " 135 290 360 365 517 345 349 560 732 230 380 225 713 800  52 640 369 200\n",
      "   2 165 816 551]\n",
      "\n",
      "Unique values for column 'V2':\n",
      "[ 20  32  36  76 100 854 124 170 196 152 156 818 231 246 250 268 276 288\n",
      " 320 344 348 356 360 364 368 380 392 400 458 466 484 498 504 528 554 578\n",
      " 604 616 642 643 646 688 705 710 410 724 752 756 158 764 780 792 804 826\n",
      " 840 858 704 894]\n",
      "  Found country: Norway (578) in column 'V2'\n",
      "  Found country: Germany (276) in column 'V2'\n",
      "\n",
      "Unique values for column 'V2A':\n",
      "[ 20  32  36  76 100 854 124 170 196 152 156 818 231 246 250 268 900 901\n",
      " 288 320 344 348 356 360 364 368 380 392 400 458 466 484 498 504 528 554\n",
      " 578 604 616 642 643 646 688 705 710 410 724 752 756 158 764 780 792 804\n",
      " 826 840 858 704 894]\n",
      "  Found country: Norway (578) in column 'V2A'\n",
      "\n",
      "Checking country codes in ./../data/raw/WV6_Data_csv_v20201117.csv:\n",
      "\n",
      "Unique values for column 'C_COW_ALPHA':\n",
      "['ALG' 'ARG' 'ARM' 'AUL' 'AZE' 'BLR' 'BRA' 'COL' 'CYP' 'CHL' 'CHN' 'ECU'\n",
      " 'EGY' 'EST' 'GRG' 'GMY' 'GHA' 'HAI' 'HKG' 'IND' 'IRQ' 'JPN' 'JOR' 'KZK'\n",
      " 'KUW' 'KYR' 'LEB' 'LIB' 'MAL' 'MEX' 'MOR' 'NTH' 'NEW' 'NIG' 'PAK' 'PSE'\n",
      " 'PER' 'PHI' 'POL' 'QAT' 'ROM' 'RUS' 'RWA' 'SIN' 'SLV' 'ROK' 'SAF' 'SPN'\n",
      " 'SWD' 'TAW' 'THI' 'TRI' 'TUN' 'TUR' 'UKR' 'USA' 'URU' 'UZB' 'YEM' 'ZIM']\n",
      "\n",
      "Unique values for column 'B_COUNTRY_ALPHA':\n",
      "['DZA' 'ARG' 'ARM' 'AUS' 'AZE' 'BLR' 'BRA' 'COL' 'CYP' 'CHL' 'CHN' 'ECU'\n",
      " 'EGY' 'EST' 'GEO' 'DEU' 'GHA' 'HTI' 'HKG' 'IND' 'IRQ' 'JPN' 'JOR' 'KAZ'\n",
      " 'KWT' 'KGZ' 'LBN' 'LBY' 'MYS' 'MEX' 'MAR' 'NLD' 'NZL' 'NGA' 'PAK' 'PSE'\n",
      " 'PER' 'PHL' 'POL' 'QAT' 'ROU' 'RUS' 'RWA' 'SGP' 'SVN' 'KOR' 'ZAF' 'ESP'\n",
      " 'SWE' 'TWN' 'THA' 'TTO' 'TUN' 'TUR' 'UKR' 'USA' 'URY' 'UZB' 'YEM' 'ZWE']\n",
      "\n",
      "Unique values for column 'COW':\n",
      "[615 160 371 900 373 370 140 100 352 155 710 130 651 366 372 255 452  41\n",
      " 714 750 645 740 663 705 690 703 660 620 820  70 600 210 920 475 770 667\n",
      " 135 840 290 694 360 365 517 830 349 732 560 230 380 713 800  52 616 640\n",
      " 369   2 165 704 679 552]\n",
      "\n",
      "Unique values for column 'V2':\n",
      "[ 12  32  51  36  31 112  76 170 196 152 156 218 818 233 268 276 288 332\n",
      " 344 356 368 392 400 398 414 417 422 434 458 484 504 528 554 566 586 275\n",
      " 604 608 616 634 642 643 646 702 705 410 710 724 752 158 764 780 788 792\n",
      " 804 840 858 860 887 716]\n",
      "  Found country: Germany (276) in column 'V2'\n",
      "\n",
      "Unique values for column 'V2A':\n",
      "[ 12  32  51  36  31 112  76 170 196 152 156 218 818 233 268 900 901 288\n",
      " 332 344 356 368 392 400 398 414 417 422 434 458 484 504 528 554 566 586\n",
      " 275 604 608 616 634 642 643 646 702 705 410 710 724 752 158 764 780 788\n",
      " 792 804 840 858 860 887 716]\n",
      "\n",
      "Checking country codes in ./../data/raw/WV7_Cross-National_Wave_7_csv_v6_0.csv:\n",
      "Warning: Missing columns in ./../data/raw/WV7_Cross-National_Wave_7_csv_v6_0.csv: C_COW_ALPHA, B_COUNTRY_ALPHA, COW, V2, V2A\n"
     ]
    }
   ],
   "source": [
    "# Print the list of raw files\n",
    "print(f\"Raw files: {raw_files}\")\n",
    "\n",
    "# Loop through each file and print unique values for the available columns\n",
    "for csv_file in raw_files:\n",
    "    print(f\"\\nChecking country codes in {csv_file}:\")\n",
    "\n",
    "    try:\n",
    "        # Read the CSV file into a dataframe\n",
    "        dataframe = pd.read_csv(csv_file, on_bad_lines='skip', delimiter=';', low_memory=False)\n",
    "\n",
    "        # Check which columns from specific_columns are available in the dataframe\n",
    "        available_columns = [col for col in specific_columns if col in dataframe.columns]\n",
    "        missing_columns = [col for col in specific_columns if col not in dataframe.columns]\n",
    "\n",
    "        # If there are missing columns, print which ones are missing\n",
    "        if missing_columns:\n",
    "            print(f\"Warning: Missing columns in {csv_file}: {', '.join(missing_columns)}\")\n",
    "\n",
    "        # Loop through the available columns and print the unique values\n",
    "        for col in available_columns:\n",
    "            print(f\"\\nUnique values for column '{col}':\")\n",
    "            unique_values = dataframe[col].unique()  # Get unique values of the column\n",
    "            print(unique_values)\n",
    "\n",
    "            # Check if any country code is contained in the unique values of the column\n",
    "            for country_code, country_name in countries:\n",
    "                if country_code in unique_values:\n",
    "                    print(f\"  Found country: {country_name} ({country_code}) in column '{col}'\")\n",
    "\n",
    "    except pd.errors.ParserError as e:\n",
    "        print(f\"Error reading {csv_file}: {e}\")\n",
    "    except ValueError as e:\n",
    "        print(f\"ValueError in {csv_file}: {e} - Columns not found.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
